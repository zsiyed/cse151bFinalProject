{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b9b2344-dd7c-40a2-aebd-31a0d80c9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, GPT2Tokenizer\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20b2273d-636b-40bf-b740-0a718282ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success is a small sum, always worth an enormous sum. The most serious mistake is an old one. Do not let your old mistakes teach you anything new. Happiness will carry you to the end of your rope.       \n",
      "Success is the achievement that elevates one person to greatness and gives them the right to live and prosper.                             \n",
      "Success is the real achievementâ€”not merely a stepping stone to success, but a personal testament to the unselfish determination to undertake great things in the grandest possible terms.               \n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"./saved_gpt2\", tokenizer=tokenizer)\n",
    "\n",
    "prompt = \"Success is\"\n",
    "generated_text = generator(prompt, max_length=50, num_return_sequences=3)\n",
    "\n",
    "for text in generated_text:\n",
    "    print(text[\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154bb3c8-5313-4aa5-bccb-ed760b5b363e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
